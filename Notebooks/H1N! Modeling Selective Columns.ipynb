{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../Data/training_set_features.csv')\n",
    "labels = pd.read_csv('../Data/training_set_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(features, labels, on='respondent_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['employment_occupation', 'employment_industry', 'health_insurance', 'respondent_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_df = df.drop(columns=['h1n1_concern',\n",
    "                          'h1n1_knowledge',\n",
    "                          'doctor_recc_h1n1',\n",
    "                          'opinion_h1n1_vacc_effective',\n",
    "                          'opinion_h1n1_risk',\n",
    "                          'opinion_h1n1_sick_from_vacc',\n",
    "                          'h1n1_vaccine'])\n",
    "\n",
    "h1n1_df = df.drop(columns=['doctor_recc_seasonal',\n",
    "                          'opinion_seas_vacc_effective',\n",
    "                          'opinion_seas_risk',\n",
    "                          'opinion_seas_sick_from_vacc',\n",
    "                          'seasonal_vaccine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'sex',\n",
    "    'hhs_geo_region',\n",
    "    'census_msa',\n",
    "    'race',\n",
    "    'age_group',\n",
    "    'behavioral_face_mask',\n",
    "    'behavioral_wash_hands',\n",
    "    'behavioral_antiviral_meds',\n",
    "    'behavioral_outside_home',\n",
    "    'behavioral_large_gatherings',\n",
    "    'behavioral_touch_face',\n",
    "    'behavioral_avoidance',\n",
    "    'health_worker',\n",
    "    'child_under_6_months',\n",
    "    'chronic_med_condition',\n",
    "    'education',\n",
    "    'marital_status',\n",
    "    'employment_status',\n",
    "    'rent_or_own',\n",
    "    'doctor_recc_h1n1',\n",
    "    'doctor_recc_seasonal',\n",
    "    'income_poverty'\n",
    "]\n",
    "\n",
    "numerical_columns = [\n",
    "    'household_children',\n",
    "    'household_adults',\n",
    "    'h1n1_concern',\n",
    "    'h1n1_knowledge',\n",
    "    'opinion_h1n1_risk',\n",
    "    'opinion_h1n1_vacc_effective',\n",
    "    'opinion_h1n1_sick_from_vacc',\n",
    "    'opinion_seas_vacc_effective',\n",
    "    'opinion_seas_risk',\n",
    "    'opinion_seas_sick_from_vacc',\n",
    "    \n",
    "]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    curr_col = df[column]\n",
    "    df.loc[df[column] == 1, column] = 'Yes'\n",
    "    df.loc[df[column] == 0, column] = 'No'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seasonal_vaccine                0.000000\n",
       "census_msa                      0.000000\n",
       "hhs_geo_region                  0.000000\n",
       "sex                             0.000000\n",
       "race                            0.000000\n",
       "age_group                       0.000000\n",
       "h1n1_vaccine                    0.000000\n",
       "behavioral_face_mask            0.071142\n",
       "behavioral_wash_hands           0.157262\n",
       "behavioral_antiviral_meds       0.265848\n",
       "behavioral_outside_home         0.307036\n",
       "behavioral_large_gatherings     0.325757\n",
       "h1n1_concern                    0.344479\n",
       "h1n1_knowledge                  0.434343\n",
       "behavioral_touch_face           0.479275\n",
       "behavioral_avoidance            0.778822\n",
       "household_children              0.932340\n",
       "household_adults                0.932340\n",
       "opinion_h1n1_risk               1.452803\n",
       "opinion_h1n1_vacc_effective     1.464036\n",
       "opinion_h1n1_sick_from_vacc     1.479013\n",
       "opinion_seas_vacc_effective     1.729884\n",
       "opinion_seas_risk               1.924589\n",
       "opinion_seas_sick_from_vacc     2.010709\n",
       "health_worker                   3.010447\n",
       "child_under_6_months            3.070356\n",
       "chronic_med_condition           3.635751\n",
       "education                       5.268282\n",
       "marital_status                  5.272026\n",
       "employment_status               5.477965\n",
       "rent_or_own                     7.645936\n",
       "doctor_recc_h1n1                8.087767\n",
       "doctor_recc_seasonal            8.087767\n",
       "income_poverty                 16.561201\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.isnull().sum() / len(df)) * 100).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_columns:\n",
    "    df[column] = df[column].fillna(df[column].mean())\n",
    "\n",
    "df['health_worker'] = df['health_worker'].fillna(0)\n",
    "df['behavioral_face_mask'] = df['behavioral_face_mask'].fillna(0)\n",
    "df['behavioral_wash_hands'] = df['behavioral_wash_hands'].fillna(0)\n",
    "df['behavioral_antiviral_meds'] = df['behavioral_antiviral_meds'].fillna(0)\n",
    "df['behavioral_outside_home'] = df['behavioral_outside_home'].fillna(0)\n",
    "df['behavioral_large_gatherings'] = df['behavioral_large_gatherings'].fillna(0)\n",
    "df['behavioral_touch_face'] = df['behavioral_touch_face'].fillna(0)\n",
    "df['behavioral_avoidance'] = df['behavioral_avoidance'].fillna(0)\n",
    "df['child_under_6_months'] = df['child_under_6_months'].fillna(0)\n",
    "df['chronic_med_condition'] = df['chronic_med_condition'].fillna(0)\n",
    "df['marital_status'] = df['marital_status'].fillna('Null')\n",
    "df['rent_or_own'] = df['rent_or_own'].fillna('Null')\n",
    "df['education'] = df['education'].fillna('Some College')\n",
    "df['employment_status'] = df['employment_status'].fillna('Null')\n",
    "df['doctor_recc_h1n1'] = df['doctor_recc_h1n1'].fillna(1)\n",
    "df['doctor_recc_seasonal'] = df['doctor_recc_seasonal'].fillna(1)\n",
    "df['income_poverty'] = df['income_poverty'].fillna('Null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_these = [\n",
    "    'rent_or_own',\n",
    "    'income_poverty',\n",
    "    'employment_status',\n",
    "    'education'\n",
    "]\n",
    "\n",
    "categorical_columns = [x for x in categorical_columns if x not in drop_these]\n",
    "\n",
    "df = df.drop(columns=drop_these)\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y = df[['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "y_h1n1 = df[['h1n1_vaccine']]\n",
    "y_seas = df[['seasonal_vaccine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Binary Data for Categorical Variables\n",
    "cat_df = X[categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recat_df = pd.get_dummies(data=cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = X[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale Numerical Data\n",
    "scaler = StandardScaler()\n",
    "scaled_num = scaler.fit_transform(num_df)\n",
    "scaled_num_df = pd.DataFrame(scaled_num, index=num_df.index, columns=num_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.concat([recat_df, scaled_num_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>hhs_geo_region_atmpeygn</th>\n",
       "      <th>hhs_geo_region_bhuqouqj</th>\n",
       "      <th>hhs_geo_region_dqpwygqj</th>\n",
       "      <th>hhs_geo_region_fpwskwrf</th>\n",
       "      <th>hhs_geo_region_kbazzjca</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>...</th>\n",
       "      <th>household_children</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>-1.182177</td>\n",
       "      <td>-0.680609</td>\n",
       "      <td>-2.046928</td>\n",
       "      <td>-1.052050</td>\n",
       "      <td>-0.850610</td>\n",
       "      <td>-0.264426</td>\n",
       "      <td>-1.880954</td>\n",
       "      <td>-1.253366</td>\n",
       "      <td>-0.089516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>-1.182177</td>\n",
       "      <td>1.520279</td>\n",
       "      <td>1.195647</td>\n",
       "      <td>1.298784</td>\n",
       "      <td>1.149360</td>\n",
       "      <td>1.214180</td>\n",
       "      <td>-0.024126</td>\n",
       "      <td>-0.524309</td>\n",
       "      <td>1.426260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>1.484891</td>\n",
       "      <td>-0.680609</td>\n",
       "      <td>-0.425641</td>\n",
       "      <td>-1.052050</td>\n",
       "      <td>-0.850610</td>\n",
       "      <td>-1.003729</td>\n",
       "      <td>-0.024126</td>\n",
       "      <td>-1.253366</td>\n",
       "      <td>-0.089516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>-1.182177</td>\n",
       "      <td>-0.680609</td>\n",
       "      <td>-0.425641</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>-0.850610</td>\n",
       "      <td>1.953484</td>\n",
       "      <td>0.904289</td>\n",
       "      <td>0.933803</td>\n",
       "      <td>-0.847404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>0.151357</td>\n",
       "      <td>0.419835</td>\n",
       "      <td>-0.425641</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>-0.850610</td>\n",
       "      <td>-0.264426</td>\n",
       "      <td>-0.952540</td>\n",
       "      <td>-1.253366</td>\n",
       "      <td>1.426260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>-1.182177</td>\n",
       "      <td>0.419835</td>\n",
       "      <td>-2.046928</td>\n",
       "      <td>-1.052050</td>\n",
       "      <td>-0.850610</td>\n",
       "      <td>-1.003729</td>\n",
       "      <td>0.904289</td>\n",
       "      <td>-0.524309</td>\n",
       "      <td>-0.089516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26703</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>0.151357</td>\n",
       "      <td>-0.680609</td>\n",
       "      <td>1.195647</td>\n",
       "      <td>-0.268439</td>\n",
       "      <td>0.149375</td>\n",
       "      <td>-0.264426</td>\n",
       "      <td>0.904289</td>\n",
       "      <td>-1.253366</td>\n",
       "      <td>-0.847404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>-1.182177</td>\n",
       "      <td>0.419835</td>\n",
       "      <td>1.195647</td>\n",
       "      <td>1.298784</td>\n",
       "      <td>0.149375</td>\n",
       "      <td>-0.264426</td>\n",
       "      <td>0.904289</td>\n",
       "      <td>0.933803</td>\n",
       "      <td>-0.089516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>0.151357</td>\n",
       "      <td>-0.680609</td>\n",
       "      <td>-0.425641</td>\n",
       "      <td>-1.052050</td>\n",
       "      <td>-0.850610</td>\n",
       "      <td>-0.264426</td>\n",
       "      <td>-1.880954</td>\n",
       "      <td>-1.253366</td>\n",
       "      <td>-0.089516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578667</td>\n",
       "      <td>0.151357</td>\n",
       "      <td>-1.781053</td>\n",
       "      <td>-2.046928</td>\n",
       "      <td>-1.052050</td>\n",
       "      <td>1.149360</td>\n",
       "      <td>-1.003729</td>\n",
       "      <td>0.904289</td>\n",
       "      <td>-1.253366</td>\n",
       "      <td>-0.847404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26707 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex_Female  sex_Male  hhs_geo_region_atmpeygn  hhs_geo_region_bhuqouqj  \\\n",
       "0               1         0                        0                        0   \n",
       "1               0         1                        0                        1   \n",
       "2               0         1                        0                        0   \n",
       "3               1         0                        0                        0   \n",
       "4               1         0                        0                        0   \n",
       "...           ...       ...                      ...                      ...   \n",
       "26702           1         0                        0                        0   \n",
       "26703           0         1                        0                        0   \n",
       "26704           1         0                        0                        0   \n",
       "26705           1         0                        0                        0   \n",
       "26706           0         1                        0                        0   \n",
       "\n",
       "       hhs_geo_region_dqpwygqj  hhs_geo_region_fpwskwrf  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "...                        ...                      ...   \n",
       "26702                        0                        0   \n",
       "26703                        0                        0   \n",
       "26704                        0                        0   \n",
       "26705                        0                        0   \n",
       "26706                        0                        0   \n",
       "\n",
       "       hhs_geo_region_kbazzjca  hhs_geo_region_lrircsnp  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        1   \n",
       "4                            0                        0   \n",
       "...                        ...                      ...   \n",
       "26702                        0                        0   \n",
       "26703                        0                        0   \n",
       "26704                        0                        0   \n",
       "26705                        0                        1   \n",
       "26706                        0                        0   \n",
       "\n",
       "       hhs_geo_region_lzgpxyit  hhs_geo_region_mlyzmhmf  ...  \\\n",
       "0                            0                        0  ...   \n",
       "1                            0                        0  ...   \n",
       "2                            0                        0  ...   \n",
       "3                            0                        0  ...   \n",
       "4                            0                        0  ...   \n",
       "...                        ...                      ...  ...   \n",
       "26702                        0                        0  ...   \n",
       "26703                        1                        0  ...   \n",
       "26704                        1                        0  ...   \n",
       "26705                        0                        0  ...   \n",
       "26706                        0                        1  ...   \n",
       "\n",
       "       household_children  household_adults  h1n1_concern  h1n1_knowledge  \\\n",
       "0               -0.578667         -1.182177     -0.680609       -2.046928   \n",
       "1               -0.578667         -1.182177      1.520279        1.195647   \n",
       "2               -0.578667          1.484891     -0.680609       -0.425641   \n",
       "3               -0.578667         -1.182177     -0.680609       -0.425641   \n",
       "4               -0.578667          0.151357      0.419835       -0.425641   \n",
       "...                   ...               ...           ...             ...   \n",
       "26702           -0.578667         -1.182177      0.419835       -2.046928   \n",
       "26703           -0.578667          0.151357     -0.680609        1.195647   \n",
       "26704           -0.578667         -1.182177      0.419835        1.195647   \n",
       "26705           -0.578667          0.151357     -0.680609       -0.425641   \n",
       "26706           -0.578667          0.151357     -1.781053       -2.046928   \n",
       "\n",
       "       opinion_h1n1_risk  opinion_h1n1_vacc_effective  \\\n",
       "0              -1.052050                    -0.850610   \n",
       "1               1.298784                     1.149360   \n",
       "2              -1.052050                    -0.850610   \n",
       "3               0.515173                    -0.850610   \n",
       "4               0.515173                    -0.850610   \n",
       "...                  ...                          ...   \n",
       "26702          -1.052050                    -0.850610   \n",
       "26703          -0.268439                     0.149375   \n",
       "26704           1.298784                     0.149375   \n",
       "26705          -1.052050                    -0.850610   \n",
       "26706          -1.052050                     1.149360   \n",
       "\n",
       "       opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "0                        -0.264426                    -1.880954   \n",
       "1                         1.214180                    -0.024126   \n",
       "2                        -1.003729                    -0.024126   \n",
       "3                         1.953484                     0.904289   \n",
       "4                        -0.264426                    -0.952540   \n",
       "...                            ...                          ...   \n",
       "26702                    -1.003729                     0.904289   \n",
       "26703                    -0.264426                     0.904289   \n",
       "26704                    -0.264426                     0.904289   \n",
       "26705                    -0.264426                    -1.880954   \n",
       "26706                    -1.003729                     0.904289   \n",
       "\n",
       "       opinion_seas_risk  opinion_seas_sick_from_vacc  \n",
       "0              -1.253366                    -0.089516  \n",
       "1              -0.524309                     1.426260  \n",
       "2              -1.253366                    -0.089516  \n",
       "3               0.933803                    -0.847404  \n",
       "4              -1.253366                     1.426260  \n",
       "...                  ...                          ...  \n",
       "26702          -0.524309                    -0.089516  \n",
       "26703          -1.253366                    -0.847404  \n",
       "26704           0.933803                    -0.089516  \n",
       "26705          -1.253366                    -0.089516  \n",
       "26706          -1.253366                    -0.847404  \n",
       "\n",
       "[26707 rows x 73 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "X = np.asarray(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex_Female', 'sex_Male', 'hhs_geo_region_atmpeygn',\n",
       "       'hhs_geo_region_bhuqouqj', 'hhs_geo_region_dqpwygqj',\n",
       "       'hhs_geo_region_fpwskwrf', 'hhs_geo_region_kbazzjca',\n",
       "       'hhs_geo_region_lrircsnp', 'hhs_geo_region_lzgpxyit',\n",
       "       'hhs_geo_region_mlyzmhmf', 'hhs_geo_region_oxchjgsf',\n",
       "       'hhs_geo_region_qufhixun', 'census_msa_MSA, Not Principle  City',\n",
       "       'census_msa_MSA, Principle City', 'census_msa_Non-MSA', 'race_Black',\n",
       "       'race_Hispanic', 'race_Other or Multiple', 'race_White',\n",
       "       'age_group_18 - 34 Years', 'age_group_35 - 44 Years',\n",
       "       'age_group_45 - 54 Years', 'age_group_55 - 64 Years',\n",
       "       'age_group_65+ Years', 'behavioral_face_mask_0',\n",
       "       'behavioral_face_mask_No', 'behavioral_face_mask_Yes',\n",
       "       'behavioral_wash_hands_0', 'behavioral_wash_hands_No',\n",
       "       'behavioral_wash_hands_Yes', 'behavioral_antiviral_meds_0',\n",
       "       'behavioral_antiviral_meds_No', 'behavioral_antiviral_meds_Yes',\n",
       "       'behavioral_outside_home_0', 'behavioral_outside_home_No',\n",
       "       'behavioral_outside_home_Yes', 'behavioral_large_gatherings_0',\n",
       "       'behavioral_large_gatherings_No', 'behavioral_large_gatherings_Yes',\n",
       "       'behavioral_touch_face_0', 'behavioral_touch_face_No',\n",
       "       'behavioral_touch_face_Yes', 'behavioral_avoidance_0',\n",
       "       'behavioral_avoidance_No', 'behavioral_avoidance_Yes',\n",
       "       'health_worker_0', 'health_worker_No', 'health_worker_Yes',\n",
       "       'child_under_6_months_0', 'child_under_6_months_No',\n",
       "       'child_under_6_months_Yes', 'chronic_med_condition_0',\n",
       "       'chronic_med_condition_No', 'chronic_med_condition_Yes',\n",
       "       'marital_status_Married', 'marital_status_Not Married',\n",
       "       'marital_status_Null', 'doctor_recc_h1n1_1', 'doctor_recc_h1n1_No',\n",
       "       'doctor_recc_h1n1_Yes', 'doctor_recc_seasonal_1',\n",
       "       'doctor_recc_seasonal_No', 'doctor_recc_seasonal_Yes',\n",
       "       'household_children', 'household_adults', 'h1n1_concern',\n",
       "       'h1n1_knowledge', 'opinion_h1n1_risk', 'opinion_h1n1_vacc_effective',\n",
       "       'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2, activation='relu', input_dim=73),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='tanh'),\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.2920 - val_loss: 0.4609 - val_accuracy: 0.2854\n",
      "Epoch 2/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.2916 - val_loss: 0.4500 - val_accuracy: 0.2854\n",
      "Epoch 3/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.2916 - val_loss: 0.4469 - val_accuracy: 0.2854\n",
      "Epoch 4/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.2916 - val_loss: 0.4446 - val_accuracy: 0.2854\n",
      "Epoch 5/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.2916 - val_loss: 0.4412 - val_accuracy: 0.2854\n",
      "Epoch 6/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.2916 - val_loss: 0.4403 - val_accuracy: 0.2854\n",
      "Epoch 7/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.2916 - val_loss: 0.4346 - val_accuracy: 0.2854\n",
      "Epoch 8/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.2916 - val_loss: 0.4299 - val_accuracy: 0.2854\n",
      "Epoch 9/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.2916 - val_loss: 0.4265 - val_accuracy: 0.2854\n",
      "Epoch 10/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.2916 - val_loss: 0.4264 - val_accuracy: 0.2854\n",
      "Epoch 11/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.2916 - val_loss: 0.4279 - val_accuracy: 0.2854\n",
      "Epoch 12/5000\n",
      "94/94 [==============================] - 0s 996us/step - loss: 0.4334 - accuracy: 0.2916 - val_loss: 0.4222 - val_accuracy: 0.2854\n",
      "Epoch 13/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.2916 - val_loss: 0.4233 - val_accuracy: 0.2854\n",
      "Epoch 14/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.2920 - val_loss: 0.4249 - val_accuracy: 0.2889\n",
      "Epoch 15/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.2929 - val_loss: 0.4217 - val_accuracy: 0.2868\n",
      "Epoch 16/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.2984 - val_loss: 0.4248 - val_accuracy: 0.2965\n",
      "Epoch 17/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.2999 - val_loss: 0.4244 - val_accuracy: 0.2994\n",
      "Epoch 18/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.3065 - val_loss: 0.4244 - val_accuracy: 0.3025\n",
      "Epoch 19/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.3045 - val_loss: 0.4252 - val_accuracy: 0.3024\n",
      "Epoch 20/5000\n",
      "94/94 [==============================] - 0s 997us/step - loss: 0.4291 - accuracy: 0.3083 - val_loss: 0.4219 - val_accuracy: 0.3001\n",
      "Epoch 21/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.3086 - val_loss: 0.4241 - val_accuracy: 0.3058\n",
      "Epoch 22/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.3083 - val_loss: 0.4235 - val_accuracy: 0.3053\n",
      "Epoch 23/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.3087 - val_loss: 0.4221 - val_accuracy: 0.2995\n",
      "Epoch 24/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.3068 - val_loss: 0.4224 - val_accuracy: 0.2978\n",
      "Epoch 25/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.3065 - val_loss: 0.4211 - val_accuracy: 0.2969\n",
      "Epoch 26/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3022 - val_loss: 0.4261 - val_accuracy: 0.3202\n",
      "Epoch 27/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.3118 - val_loss: 0.4220 - val_accuracy: 0.2999\n",
      "Epoch 28/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3021 - val_loss: 0.4221 - val_accuracy: 0.3000\n",
      "Epoch 29/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.3134 - val_loss: 0.4267 - val_accuracy: 0.3116\n",
      "Epoch 30/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.3051 - val_loss: 0.4242 - val_accuracy: 0.3056\n",
      "Epoch 31/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.3084 - val_loss: 0.4190 - val_accuracy: 0.2922\n",
      "Epoch 32/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3076 - val_loss: 0.4196 - val_accuracy: 0.2939\n",
      "Epoch 33/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3106 - val_loss: 0.4228 - val_accuracy: 0.3058\n",
      "Epoch 34/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3119 - val_loss: 0.4222 - val_accuracy: 0.3051\n",
      "Epoch 35/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3097 - val_loss: 0.4215 - val_accuracy: 0.2955\n",
      "Epoch 36/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3177 - val_loss: 0.4230 - val_accuracy: 0.3109\n",
      "Epoch 37/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.3577 - val_loss: 0.4212 - val_accuracy: 0.3073\n",
      "Epoch 38/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3347 - val_loss: 0.4259 - val_accuracy: 0.3940\n",
      "Epoch 39/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.3785 - val_loss: 0.4212 - val_accuracy: 0.3618\n",
      "Epoch 40/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3805 - val_loss: 0.4247 - val_accuracy: 0.4118\n",
      "Epoch 41/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3906 - val_loss: 0.4223 - val_accuracy: 0.3801\n",
      "Epoch 42/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3894 - val_loss: 0.4221 - val_accuracy: 0.3642\n",
      "Epoch 43/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3477 - val_loss: 0.4229 - val_accuracy: 0.3663\n",
      "Epoch 44/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3179 - val_loss: 0.4216 - val_accuracy: 0.3559\n",
      "Epoch 45/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3506 - val_loss: 0.4193 - val_accuracy: 0.2934\n",
      "Epoch 46/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3743 - val_loss: 0.4230 - val_accuracy: 0.3660\n",
      "Epoch 47/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3212 - val_loss: 0.4233 - val_accuracy: 0.2954\n",
      "Epoch 48/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3126 - val_loss: 0.4229 - val_accuracy: 0.2941\n",
      "Epoch 49/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3367 - val_loss: 0.4212 - val_accuracy: 0.3618\n",
      "Epoch 50/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.3709 - val_loss: 0.4226 - val_accuracy: 0.3673\n",
      "Epoch 51/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3763 - val_loss: 0.4229 - val_accuracy: 0.3688\n",
      "Epoch 52/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3739 - val_loss: 0.4217 - val_accuracy: 0.3555\n",
      "Epoch 53/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3765 - val_loss: 0.4239 - val_accuracy: 0.3659\n",
      "Epoch 54/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3674 - val_loss: 0.4216 - val_accuracy: 0.3605\n",
      "Epoch 55/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3752 - val_loss: 0.4214 - val_accuracy: 0.3635\n",
      "Epoch 56/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3829 - val_loss: 0.4236 - val_accuracy: 0.3650\n",
      "Epoch 57/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3740 - val_loss: 0.4205 - val_accuracy: 0.3617\n",
      "Epoch 58/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3742 - val_loss: 0.4219 - val_accuracy: 0.3675\n",
      "Epoch 59/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3740 - val_loss: 0.4196 - val_accuracy: 0.3612\n",
      "Epoch 60/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3735 - val_loss: 0.4236 - val_accuracy: 0.3609\n",
      "Epoch 61/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3742 - val_loss: 0.4229 - val_accuracy: 0.3638\n",
      "Epoch 62/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3735 - val_loss: 0.4221 - val_accuracy: 0.3614\n",
      "Epoch 63/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3743 - val_loss: 0.4214 - val_accuracy: 0.3650\n",
      "Epoch 64/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.3787 - val_loss: 0.4226 - val_accuracy: 0.3643\n",
      "Epoch 65/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3763 - val_loss: 0.4230 - val_accuracy: 0.3633\n",
      "Epoch 66/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3763 - val_loss: 0.4225 - val_accuracy: 0.3618\n",
      "Epoch 67/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3773 - val_loss: 0.4214 - val_accuracy: 0.3630\n",
      "Epoch 68/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3764 - val_loss: 0.4208 - val_accuracy: 0.3640\n",
      "Epoch 69/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3778 - val_loss: 0.4207 - val_accuracy: 0.3654\n",
      "Epoch 70/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3784 - val_loss: 0.4209 - val_accuracy: 0.3634\n",
      "Epoch 71/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3773 - val_loss: 0.4212 - val_accuracy: 0.3694\n",
      "Epoch 72/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3792 - val_loss: 0.4180 - val_accuracy: 0.3645\n",
      "Epoch 73/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3797 - val_loss: 0.4211 - val_accuracy: 0.3663\n",
      "Epoch 74/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3766 - val_loss: 0.4200 - val_accuracy: 0.3655\n",
      "Epoch 75/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.3769 - val_loss: 0.4224 - val_accuracy: 0.3642\n",
      "Epoch 76/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3773 - val_loss: 0.4236 - val_accuracy: 0.3658\n",
      "Epoch 77/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3774 - val_loss: 0.4217 - val_accuracy: 0.3675\n",
      "Epoch 78/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3784 - val_loss: 0.4209 - val_accuracy: 0.3618\n",
      "Epoch 79/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.3774 - val_loss: 0.4202 - val_accuracy: 0.3648\n",
      "Epoch 80/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3773 - val_loss: 0.4204 - val_accuracy: 0.3688\n",
      "Epoch 81/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.3785 - val_loss: 0.4216 - val_accuracy: 0.3648\n",
      "Epoch 82/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3788 - val_loss: 0.4211 - val_accuracy: 0.3639\n",
      "Epoch 83/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3789 - val_loss: 0.4216 - val_accuracy: 0.3687\n",
      "Epoch 84/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3781 - val_loss: 0.4202 - val_accuracy: 0.3680\n",
      "Epoch 85/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3794 - val_loss: 0.4203 - val_accuracy: 0.3679\n",
      "Epoch 86/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3783 - val_loss: 0.4222 - val_accuracy: 0.3678\n",
      "Epoch 87/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3780 - val_loss: 0.4203 - val_accuracy: 0.3647\n",
      "Epoch 88/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3786 - val_loss: 0.4224 - val_accuracy: 0.3678\n",
      "Epoch 89/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3789 - val_loss: 0.4223 - val_accuracy: 0.3670\n",
      "Epoch 90/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3796 - val_loss: 0.4232 - val_accuracy: 0.3675\n",
      "Epoch 91/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3805 - val_loss: 0.4228 - val_accuracy: 0.3710\n",
      "Epoch 92/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3788 - val_loss: 0.4251 - val_accuracy: 0.3673\n",
      "Epoch 93/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3792 - val_loss: 0.4230 - val_accuracy: 0.3668\n",
      "Epoch 94/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3786 - val_loss: 0.4219 - val_accuracy: 0.3652\n",
      "Epoch 95/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3799 - val_loss: 0.4215 - val_accuracy: 0.3668\n",
      "Epoch 96/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3796 - val_loss: 0.4227 - val_accuracy: 0.3693\n",
      "Epoch 97/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3795 - val_loss: 0.4232 - val_accuracy: 0.3678\n",
      "Epoch 98/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3774 - val_loss: 0.4229 - val_accuracy: 0.3662\n",
      "Epoch 99/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3801 - val_loss: 0.4221 - val_accuracy: 0.3674\n",
      "Epoch 100/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3789 - val_loss: 0.4220 - val_accuracy: 0.3679\n",
      "Epoch 101/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3794 - val_loss: 0.4232 - val_accuracy: 0.3688\n",
      "Epoch 102/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3799 - val_loss: 0.4237 - val_accuracy: 0.3652\n",
      "Epoch 103/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3781 - val_loss: 0.4224 - val_accuracy: 0.3664\n",
      "Epoch 104/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3797 - val_loss: 0.4233 - val_accuracy: 0.3662\n",
      "Epoch 105/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3799 - val_loss: 0.4229 - val_accuracy: 0.3648\n",
      "Epoch 106/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3804 - val_loss: 0.4224 - val_accuracy: 0.3664\n",
      "Epoch 107/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3804 - val_loss: 0.4215 - val_accuracy: 0.3683\n",
      "Epoch 108/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3816 - val_loss: 0.4240 - val_accuracy: 0.3679\n",
      "Epoch 109/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3804 - val_loss: 0.4197 - val_accuracy: 0.3673\n",
      "Epoch 110/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3799 - val_loss: 0.4219 - val_accuracy: 0.3695\n",
      "Epoch 111/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3801 - val_loss: 0.4218 - val_accuracy: 0.3738\n",
      "Epoch 112/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3812 - val_loss: 0.4241 - val_accuracy: 0.3721\n",
      "Epoch 113/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3808 - val_loss: 0.4222 - val_accuracy: 0.3665\n",
      "Epoch 114/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3804 - val_loss: 0.4228 - val_accuracy: 0.3689\n",
      "Epoch 115/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3788 - val_loss: 0.4220 - val_accuracy: 0.3682\n",
      "Epoch 116/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3818 - val_loss: 0.4213 - val_accuracy: 0.3667\n",
      "Epoch 117/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3821 - val_loss: 0.4208 - val_accuracy: 0.3667\n",
      "Epoch 118/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3809 - val_loss: 0.4228 - val_accuracy: 0.3699\n",
      "Epoch 119/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3823 - val_loss: 0.4218 - val_accuracy: 0.3645\n",
      "Epoch 120/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3804 - val_loss: 0.4214 - val_accuracy: 0.3692\n",
      "Epoch 121/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3812 - val_loss: 0.4227 - val_accuracy: 0.3710\n",
      "Epoch 122/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3807 - val_loss: 0.4219 - val_accuracy: 0.3692\n",
      "Epoch 123/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3820 - val_loss: 0.4226 - val_accuracy: 0.3670\n",
      "Epoch 124/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3822 - val_loss: 0.4235 - val_accuracy: 0.3693\n",
      "Epoch 125/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3813 - val_loss: 0.4223 - val_accuracy: 0.3650\n",
      "Epoch 126/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3797 - val_loss: 0.4221 - val_accuracy: 0.3692\n",
      "Epoch 127/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3810 - val_loss: 0.4226 - val_accuracy: 0.3683\n",
      "Epoch 128/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3800 - val_loss: 0.4209 - val_accuracy: 0.3672\n",
      "Epoch 129/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3801 - val_loss: 0.4201 - val_accuracy: 0.3677\n",
      "Epoch 130/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3822 - val_loss: 0.4224 - val_accuracy: 0.3690\n",
      "Epoch 131/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3817 - val_loss: 0.4223 - val_accuracy: 0.3680\n",
      "Epoch 132/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3809 - val_loss: 0.4218 - val_accuracy: 0.3699\n",
      "Epoch 133/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3813 - val_loss: 0.4226 - val_accuracy: 0.3682\n",
      "Epoch 134/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3795 - val_loss: 0.4215 - val_accuracy: 0.3649\n",
      "Epoch 135/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3803 - val_loss: 0.4213 - val_accuracy: 0.3682\n",
      "Epoch 136/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3816 - val_loss: 0.4229 - val_accuracy: 0.3677\n",
      "Epoch 137/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3805 - val_loss: 0.4212 - val_accuracy: 0.3684\n",
      "Epoch 138/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3786 - val_loss: 0.4237 - val_accuracy: 0.3700\n",
      "Epoch 139/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3824 - val_loss: 0.4204 - val_accuracy: 0.3705\n",
      "Epoch 140/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3825 - val_loss: 0.4230 - val_accuracy: 0.3677\n",
      "Epoch 141/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3820 - val_loss: 0.4224 - val_accuracy: 0.3672\n",
      "Epoch 142/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.3821 - val_loss: 0.4227 - val_accuracy: 0.3689\n",
      "Epoch 143/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3799 - val_loss: 0.4227 - val_accuracy: 0.3622\n",
      "Epoch 144/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3815 - val_loss: 0.4219 - val_accuracy: 0.3703\n",
      "Epoch 145/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3816 - val_loss: 0.4237 - val_accuracy: 0.3709\n",
      "Epoch 146/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3823 - val_loss: 0.4216 - val_accuracy: 0.3683\n",
      "Epoch 147/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3819 - val_loss: 0.4227 - val_accuracy: 0.3662\n",
      "Epoch 148/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3830 - val_loss: 0.4239 - val_accuracy: 0.3692\n",
      "Epoch 149/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3821 - val_loss: 0.4243 - val_accuracy: 0.3670\n",
      "Epoch 150/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3821 - val_loss: 0.4213 - val_accuracy: 0.3718\n",
      "Epoch 151/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3814 - val_loss: 0.4238 - val_accuracy: 0.3698\n",
      "Epoch 152/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3821 - val_loss: 0.4233 - val_accuracy: 0.3703\n",
      "Epoch 153/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3823 - val_loss: 0.4234 - val_accuracy: 0.3682\n",
      "Epoch 154/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3830 - val_loss: 0.4229 - val_accuracy: 0.3700\n",
      "Epoch 155/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3816 - val_loss: 0.4220 - val_accuracy: 0.3688\n",
      "Epoch 156/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3820 - val_loss: 0.4220 - val_accuracy: 0.3726\n",
      "Epoch 157/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3826 - val_loss: 0.4244 - val_accuracy: 0.3683\n",
      "Epoch 158/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.3821 - val_loss: 0.4219 - val_accuracy: 0.3672\n",
      "Epoch 159/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3833 - val_loss: 0.4235 - val_accuracy: 0.3698\n",
      "Epoch 160/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3816 - val_loss: 0.4217 - val_accuracy: 0.3679\n",
      "Epoch 161/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3826 - val_loss: 0.4228 - val_accuracy: 0.3667\n",
      "Epoch 162/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3835 - val_loss: 0.4230 - val_accuracy: 0.3684\n",
      "Epoch 163/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3820 - val_loss: 0.4226 - val_accuracy: 0.3667\n",
      "Epoch 164/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3818 - val_loss: 0.4223 - val_accuracy: 0.3668\n",
      "Epoch 165/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3813 - val_loss: 0.4235 - val_accuracy: 0.3694\n",
      "Epoch 166/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3810 - val_loss: 0.4225 - val_accuracy: 0.3680\n",
      "Epoch 167/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3816 - val_loss: 0.4237 - val_accuracy: 0.3674\n",
      "Epoch 168/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3821 - val_loss: 0.4230 - val_accuracy: 0.3679\n",
      "Epoch 169/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3819 - val_loss: 0.4232 - val_accuracy: 0.3669\n",
      "Epoch 170/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3823 - val_loss: 0.4224 - val_accuracy: 0.3709\n",
      "Epoch 171/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3827 - val_loss: 0.4237 - val_accuracy: 0.3696\n",
      "Epoch 172/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3827 - val_loss: 0.4209 - val_accuracy: 0.3696\n",
      "Epoch 173/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3830 - val_loss: 0.4238 - val_accuracy: 0.3716\n",
      "Epoch 174/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3837 - val_loss: 0.4240 - val_accuracy: 0.3658\n",
      "Epoch 175/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3817 - val_loss: 0.4228 - val_accuracy: 0.3699\n",
      "Epoch 176/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.3837 - val_loss: 0.4231 - val_accuracy: 0.3709\n",
      "Epoch 177/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3801 - val_loss: 0.4214 - val_accuracy: 0.3677\n",
      "Epoch 178/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3822 - val_loss: 0.4211 - val_accuracy: 0.3710\n",
      "Epoch 179/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3840 - val_loss: 0.4232 - val_accuracy: 0.3669\n",
      "Epoch 180/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3826 - val_loss: 0.4234 - val_accuracy: 0.3704\n",
      "Epoch 181/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3818 - val_loss: 0.4199 - val_accuracy: 0.3660\n",
      "Epoch 182/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3817 - val_loss: 0.4212 - val_accuracy: 0.3678\n",
      "Epoch 183/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3818 - val_loss: 0.4225 - val_accuracy: 0.3687\n",
      "Epoch 184/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3834 - val_loss: 0.4230 - val_accuracy: 0.3668\n",
      "Epoch 185/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3840 - val_loss: 0.4207 - val_accuracy: 0.3649\n",
      "Epoch 186/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3800 - val_loss: 0.4247 - val_accuracy: 0.3682\n",
      "Epoch 187/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3833 - val_loss: 0.4213 - val_accuracy: 0.3653\n",
      "Epoch 188/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3816 - val_loss: 0.4234 - val_accuracy: 0.3680\n",
      "Epoch 189/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3823 - val_loss: 0.4243 - val_accuracy: 0.3680\n",
      "Epoch 190/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.3836 - val_loss: 0.4200 - val_accuracy: 0.3679\n",
      "Epoch 191/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3840 - val_loss: 0.4215 - val_accuracy: 0.3688\n",
      "Epoch 192/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3833 - val_loss: 0.4224 - val_accuracy: 0.3668\n",
      "Epoch 193/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3820 - val_loss: 0.4220 - val_accuracy: 0.3683\n",
      "Epoch 194/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3815 - val_loss: 0.4224 - val_accuracy: 0.3670\n",
      "Epoch 195/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3815 - val_loss: 0.4223 - val_accuracy: 0.3683\n",
      "Epoch 196/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3827 - val_loss: 0.4229 - val_accuracy: 0.3709\n",
      "Epoch 197/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3835 - val_loss: 0.4226 - val_accuracy: 0.3669\n",
      "Epoch 198/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3833 - val_loss: 0.4212 - val_accuracy: 0.3692\n",
      "Epoch 199/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3834 - val_loss: 0.4223 - val_accuracy: 0.3655\n",
      "Epoch 200/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3805 - val_loss: 0.4218 - val_accuracy: 0.3674\n",
      "Epoch 201/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3824 - val_loss: 0.4214 - val_accuracy: 0.3670\n",
      "Epoch 202/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3848 - val_loss: 0.4229 - val_accuracy: 0.3685\n",
      "Epoch 203/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3837 - val_loss: 0.4208 - val_accuracy: 0.3679\n",
      "Epoch 204/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3816 - val_loss: 0.4217 - val_accuracy: 0.3670\n",
      "Epoch 205/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3830 - val_loss: 0.4222 - val_accuracy: 0.3662\n",
      "Epoch 206/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3816 - val_loss: 0.4225 - val_accuracy: 0.3672\n",
      "Epoch 207/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3817 - val_loss: 0.4219 - val_accuracy: 0.3664\n",
      "Epoch 208/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3823 - val_loss: 0.4229 - val_accuracy: 0.3667\n",
      "Epoch 209/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.3809 - val_loss: 0.4240 - val_accuracy: 0.3669\n",
      "Epoch 210/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.3828 - val_loss: 0.4233 - val_accuracy: 0.3679\n",
      "Epoch 211/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3832 - val_loss: 0.4230 - val_accuracy: 0.3690\n",
      "Epoch 212/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3822 - val_loss: 0.4228 - val_accuracy: 0.3677\n",
      "Epoch 213/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3819 - val_loss: 0.4228 - val_accuracy: 0.3677\n",
      "Epoch 214/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3831 - val_loss: 0.4237 - val_accuracy: 0.3677\n",
      "Epoch 215/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3826 - val_loss: 0.4228 - val_accuracy: 0.3675\n",
      "Epoch 216/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3835 - val_loss: 0.4219 - val_accuracy: 0.3667\n",
      "Epoch 217/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3812 - val_loss: 0.4219 - val_accuracy: 0.3650\n",
      "Epoch 218/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3815 - val_loss: 0.4237 - val_accuracy: 0.3667\n",
      "Epoch 219/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.3824 - val_loss: 0.4215 - val_accuracy: 0.3678\n",
      "Epoch 220/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3820 - val_loss: 0.4221 - val_accuracy: 0.3673\n",
      "Epoch 221/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3820 - val_loss: 0.4222 - val_accuracy: 0.3683\n",
      "Epoch 222/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3825 - val_loss: 0.4245 - val_accuracy: 0.3695\n",
      "Epoch 223/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3813 - val_loss: 0.4225 - val_accuracy: 0.3674\n",
      "Epoch 224/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3822 - val_loss: 0.4229 - val_accuracy: 0.3677\n",
      "Epoch 225/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3816 - val_loss: 0.4211 - val_accuracy: 0.3680\n",
      "Epoch 226/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3819 - val_loss: 0.4224 - val_accuracy: 0.3682\n",
      "Epoch 227/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.3822 - val_loss: 0.4223 - val_accuracy: 0.3664\n",
      "Epoch 228/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3823 - val_loss: 0.4228 - val_accuracy: 0.3695\n",
      "Epoch 229/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3827 - val_loss: 0.4226 - val_accuracy: 0.3690\n",
      "Epoch 230/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.3839 - val_loss: 0.4224 - val_accuracy: 0.3687\n",
      "Epoch 231/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3840 - val_loss: 0.4221 - val_accuracy: 0.3683\n",
      "Epoch 232/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3824 - val_loss: 0.4230 - val_accuracy: 0.3663\n",
      "Epoch 233/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3836 - val_loss: 0.4209 - val_accuracy: 0.3677\n",
      "Epoch 234/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3839 - val_loss: 0.4228 - val_accuracy: 0.3699\n",
      "Epoch 235/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3834 - val_loss: 0.4261 - val_accuracy: 0.3684\n",
      "Epoch 236/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3828 - val_loss: 0.4228 - val_accuracy: 0.3680\n",
      "Epoch 237/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3827 - val_loss: 0.4233 - val_accuracy: 0.3672\n",
      "Epoch 238/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3829 - val_loss: 0.4227 - val_accuracy: 0.3695\n",
      "Epoch 239/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3827 - val_loss: 0.4203 - val_accuracy: 0.3675\n",
      "Epoch 240/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3824 - val_loss: 0.4229 - val_accuracy: 0.3689\n",
      "Epoch 241/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3817 - val_loss: 0.4218 - val_accuracy: 0.3709\n",
      "Epoch 242/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3839 - val_loss: 0.4225 - val_accuracy: 0.3696\n",
      "Epoch 243/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3839 - val_loss: 0.4220 - val_accuracy: 0.3669\n",
      "Epoch 244/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3825 - val_loss: 0.4233 - val_accuracy: 0.3695\n",
      "Epoch 245/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3841 - val_loss: 0.4213 - val_accuracy: 0.3693\n",
      "Epoch 246/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3836 - val_loss: 0.4224 - val_accuracy: 0.3673\n",
      "Epoch 247/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3837 - val_loss: 0.4219 - val_accuracy: 0.3690\n",
      "Epoch 248/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3833 - val_loss: 0.4235 - val_accuracy: 0.3706\n",
      "Epoch 249/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3841 - val_loss: 0.4224 - val_accuracy: 0.3673\n",
      "Epoch 250/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3838 - val_loss: 0.4229 - val_accuracy: 0.3673\n",
      "Epoch 251/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3826 - val_loss: 0.4245 - val_accuracy: 0.3663\n",
      "Epoch 252/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3825 - val_loss: 0.4216 - val_accuracy: 0.3677\n",
      "Epoch 253/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3818 - val_loss: 0.4222 - val_accuracy: 0.3693\n",
      "Epoch 254/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3823 - val_loss: 0.4234 - val_accuracy: 0.3672\n",
      "Epoch 255/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3824 - val_loss: 0.4225 - val_accuracy: 0.3692\n",
      "Epoch 256/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3836 - val_loss: 0.4227 - val_accuracy: 0.3688\n",
      "Epoch 257/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3823 - val_loss: 0.4222 - val_accuracy: 0.3683\n",
      "Epoch 258/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3826 - val_loss: 0.4218 - val_accuracy: 0.3665\n",
      "Epoch 259/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3823 - val_loss: 0.4228 - val_accuracy: 0.3672\n",
      "Epoch 260/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3832 - val_loss: 0.4217 - val_accuracy: 0.3665\n",
      "Epoch 261/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3826 - val_loss: 0.4234 - val_accuracy: 0.3696\n",
      "Epoch 262/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3839 - val_loss: 0.4214 - val_accuracy: 0.3682\n",
      "Epoch 263/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3820 - val_loss: 0.4210 - val_accuracy: 0.3687\n",
      "Epoch 264/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3831 - val_loss: 0.4238 - val_accuracy: 0.3683\n",
      "Epoch 265/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3835 - val_loss: 0.4214 - val_accuracy: 0.3658\n",
      "Epoch 266/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3839 - val_loss: 0.4229 - val_accuracy: 0.3682\n",
      "Epoch 267/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3830 - val_loss: 0.4224 - val_accuracy: 0.3680\n",
      "Epoch 268/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3830 - val_loss: 0.4219 - val_accuracy: 0.3678\n",
      "Epoch 269/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3833 - val_loss: 0.4232 - val_accuracy: 0.3679\n",
      "Epoch 270/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3832 - val_loss: 0.4230 - val_accuracy: 0.3698\n",
      "Epoch 271/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3841 - val_loss: 0.4235 - val_accuracy: 0.3680\n",
      "Epoch 272/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3838 - val_loss: 0.4241 - val_accuracy: 0.3685\n",
      "Epoch 273/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3838 - val_loss: 0.4234 - val_accuracy: 0.3674\n",
      "Epoch 274/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3831 - val_loss: 0.4211 - val_accuracy: 0.3694\n",
      "Epoch 275/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3847 - val_loss: 0.4229 - val_accuracy: 0.3694\n",
      "Epoch 276/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3821 - val_loss: 0.4227 - val_accuracy: 0.3679\n",
      "Epoch 277/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.3840 - val_loss: 0.4223 - val_accuracy: 0.3683\n",
      "Epoch 278/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3837 - val_loss: 0.4215 - val_accuracy: 0.3700\n",
      "Epoch 279/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3841 - val_loss: 0.4212 - val_accuracy: 0.3685\n",
      "Epoch 280/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3854 - val_loss: 0.4231 - val_accuracy: 0.3692\n",
      "Epoch 281/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3843 - val_loss: 0.4200 - val_accuracy: 0.3648\n",
      "Epoch 282/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3826 - val_loss: 0.4229 - val_accuracy: 0.3668\n",
      "Epoch 283/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3844 - val_loss: 0.4223 - val_accuracy: 0.3657\n",
      "Epoch 284/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3823 - val_loss: 0.4205 - val_accuracy: 0.3721\n",
      "Epoch 285/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.3841 - val_loss: 0.4203 - val_accuracy: 0.3669\n",
      "Epoch 286/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3832 - val_loss: 0.4237 - val_accuracy: 0.3684\n",
      "Epoch 287/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3825 - val_loss: 0.4246 - val_accuracy: 0.3675\n",
      "Epoch 288/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3811 - val_loss: 0.4242 - val_accuracy: 0.3703\n",
      "Epoch 289/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.3849 - val_loss: 0.4233 - val_accuracy: 0.3680\n",
      "Epoch 290/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3832 - val_loss: 0.4216 - val_accuracy: 0.3690\n",
      "Epoch 291/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3835 - val_loss: 0.4232 - val_accuracy: 0.3678\n",
      "Epoch 292/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3832 - val_loss: 0.4225 - val_accuracy: 0.3674\n",
      "Epoch 293/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3818 - val_loss: 0.4230 - val_accuracy: 0.3680\n",
      "Epoch 294/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3811 - val_loss: 0.4225 - val_accuracy: 0.3679\n",
      "Epoch 295/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3835 - val_loss: 0.4226 - val_accuracy: 0.3662\n",
      "Epoch 296/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3827 - val_loss: 0.4227 - val_accuracy: 0.3692\n",
      "Epoch 297/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3834 - val_loss: 0.4205 - val_accuracy: 0.3705\n",
      "Epoch 298/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3854 - val_loss: 0.4244 - val_accuracy: 0.3687\n",
      "Epoch 299/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3826 - val_loss: 0.4227 - val_accuracy: 0.3650\n",
      "Epoch 300/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3832 - val_loss: 0.4237 - val_accuracy: 0.3698\n",
      "Epoch 301/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3844 - val_loss: 0.4234 - val_accuracy: 0.3685\n",
      "Epoch 302/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3836 - val_loss: 0.4225 - val_accuracy: 0.3675\n",
      "Epoch 303/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3817 - val_loss: 0.4238 - val_accuracy: 0.3682\n",
      "Epoch 304/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3835 - val_loss: 0.4207 - val_accuracy: 0.3662\n",
      "Epoch 305/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3827 - val_loss: 0.4225 - val_accuracy: 0.3679\n",
      "Epoch 306/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3838 - val_loss: 0.4229 - val_accuracy: 0.3711\n",
      "Epoch 307/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3834 - val_loss: 0.4233 - val_accuracy: 0.3696\n",
      "Epoch 308/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3837 - val_loss: 0.4231 - val_accuracy: 0.3689\n",
      "Epoch 309/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3837 - val_loss: 0.4235 - val_accuracy: 0.3693\n",
      "Epoch 310/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3847 - val_loss: 0.4224 - val_accuracy: 0.3706\n",
      "Epoch 311/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.3861 - val_loss: 0.4223 - val_accuracy: 0.3699\n",
      "Epoch 312/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3844 - val_loss: 0.4212 - val_accuracy: 0.3694\n",
      "Epoch 313/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3832 - val_loss: 0.4227 - val_accuracy: 0.3710\n",
      "Epoch 314/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3845 - val_loss: 0.4246 - val_accuracy: 0.3673\n",
      "Epoch 315/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3863 - val_loss: 0.4218 - val_accuracy: 0.3674\n",
      "Epoch 316/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3829 - val_loss: 0.4227 - val_accuracy: 0.3714\n",
      "Epoch 317/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3849 - val_loss: 0.4219 - val_accuracy: 0.3695\n",
      "Epoch 318/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3848 - val_loss: 0.4221 - val_accuracy: 0.3693\n",
      "Epoch 319/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3831 - val_loss: 0.4227 - val_accuracy: 0.3682\n",
      "Epoch 320/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3819 - val_loss: 0.4228 - val_accuracy: 0.3710\n",
      "Epoch 321/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3828 - val_loss: 0.4228 - val_accuracy: 0.3699\n",
      "Epoch 322/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3841 - val_loss: 0.4222 - val_accuracy: 0.3698\n",
      "Epoch 323/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3834 - val_loss: 0.4231 - val_accuracy: 0.3693\n",
      "Epoch 324/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3830 - val_loss: 0.4221 - val_accuracy: 0.3693\n",
      "Epoch 325/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3817 - val_loss: 0.4217 - val_accuracy: 0.3675\n",
      "Epoch 326/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3835 - val_loss: 0.4218 - val_accuracy: 0.3700\n",
      "Epoch 327/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3833 - val_loss: 0.4229 - val_accuracy: 0.3720\n",
      "Epoch 328/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3840 - val_loss: 0.4237 - val_accuracy: 0.3716\n",
      "Epoch 329/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.3845 - val_loss: 0.4239 - val_accuracy: 0.3690\n",
      "Epoch 330/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3835 - val_loss: 0.4232 - val_accuracy: 0.3680\n",
      "Epoch 331/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3834 - val_loss: 0.4229 - val_accuracy: 0.3674\n",
      "Epoch 332/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3834 - val_loss: 0.4235 - val_accuracy: 0.3688\n",
      "Epoch 333/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3845 - val_loss: 0.4227 - val_accuracy: 0.3715\n",
      "Epoch 334/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3838 - val_loss: 0.4219 - val_accuracy: 0.3696\n",
      "Epoch 335/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3846 - val_loss: 0.4227 - val_accuracy: 0.3694\n",
      "Epoch 336/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3841 - val_loss: 0.4226 - val_accuracy: 0.3689\n",
      "Epoch 337/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3836 - val_loss: 0.4238 - val_accuracy: 0.3710\n",
      "Epoch 338/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3837 - val_loss: 0.4218 - val_accuracy: 0.3692\n",
      "Epoch 339/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3835 - val_loss: 0.4197 - val_accuracy: 0.3710\n",
      "Epoch 340/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3837 - val_loss: 0.4222 - val_accuracy: 0.3677\n",
      "Epoch 341/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3824 - val_loss: 0.4217 - val_accuracy: 0.3677\n",
      "Epoch 342/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3839 - val_loss: 0.4234 - val_accuracy: 0.3716\n",
      "Epoch 343/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.3834 - val_loss: 0.4241 - val_accuracy: 0.3700\n",
      "Epoch 344/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3831 - val_loss: 0.4211 - val_accuracy: 0.3699\n",
      "Epoch 345/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3831 - val_loss: 0.4215 - val_accuracy: 0.3685\n",
      "Epoch 346/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3850 - val_loss: 0.4227 - val_accuracy: 0.3709\n",
      "Epoch 347/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3829 - val_loss: 0.4227 - val_accuracy: 0.3704\n",
      "Epoch 348/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3839 - val_loss: 0.4224 - val_accuracy: 0.3716\n",
      "Epoch 349/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3837 - val_loss: 0.4232 - val_accuracy: 0.3696\n",
      "Epoch 350/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3840 - val_loss: 0.4241 - val_accuracy: 0.3713\n",
      "Epoch 351/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3860 - val_loss: 0.4233 - val_accuracy: 0.3701\n",
      "Epoch 352/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3849 - val_loss: 0.4227 - val_accuracy: 0.3703\n",
      "Epoch 353/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3837 - val_loss: 0.4224 - val_accuracy: 0.3692\n",
      "Epoch 354/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3864 - val_loss: 0.4232 - val_accuracy: 0.3715\n",
      "Epoch 355/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3851 - val_loss: 0.4238 - val_accuracy: 0.3721\n",
      "Epoch 356/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3873 - val_loss: 0.4221 - val_accuracy: 0.3721\n",
      "Epoch 357/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3852 - val_loss: 0.4230 - val_accuracy: 0.3719\n",
      "Epoch 358/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3854 - val_loss: 0.4232 - val_accuracy: 0.3719\n",
      "Epoch 359/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3863 - val_loss: 0.4223 - val_accuracy: 0.3708\n",
      "Epoch 360/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3847 - val_loss: 0.4204 - val_accuracy: 0.3652\n",
      "Epoch 361/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3841 - val_loss: 0.4228 - val_accuracy: 0.3703\n",
      "Epoch 362/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3848 - val_loss: 0.4225 - val_accuracy: 0.3673\n",
      "Epoch 363/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3842 - val_loss: 0.4213 - val_accuracy: 0.3738\n",
      "Epoch 364/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3861 - val_loss: 0.4232 - val_accuracy: 0.3716\n",
      "Epoch 365/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3858 - val_loss: 0.4230 - val_accuracy: 0.3674\n",
      "Epoch 366/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3847 - val_loss: 0.4217 - val_accuracy: 0.3703\n",
      "Epoch 367/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3847 - val_loss: 0.4245 - val_accuracy: 0.3706\n",
      "Epoch 368/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3866 - val_loss: 0.4230 - val_accuracy: 0.3694\n",
      "Epoch 369/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3861 - val_loss: 0.4232 - val_accuracy: 0.3718\n",
      "Epoch 370/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3860 - val_loss: 0.4233 - val_accuracy: 0.3711\n",
      "Epoch 371/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3841 - val_loss: 0.4224 - val_accuracy: 0.3684\n",
      "Epoch 372/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3834 - val_loss: 0.4242 - val_accuracy: 0.3679\n",
      "Epoch 373/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3848 - val_loss: 0.4216 - val_accuracy: 0.3689\n",
      "Epoch 374/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3853 - val_loss: 0.4214 - val_accuracy: 0.3687\n",
      "Epoch 375/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3845 - val_loss: 0.4222 - val_accuracy: 0.3704\n",
      "Epoch 376/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3840 - val_loss: 0.4212 - val_accuracy: 0.3700\n",
      "Epoch 377/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3840 - val_loss: 0.4243 - val_accuracy: 0.3663\n",
      "Epoch 378/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3836 - val_loss: 0.4209 - val_accuracy: 0.3675\n",
      "Epoch 379/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3870 - val_loss: 0.4218 - val_accuracy: 0.3700\n",
      "Epoch 380/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3858 - val_loss: 0.4227 - val_accuracy: 0.3716\n",
      "Epoch 381/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3861 - val_loss: 0.4230 - val_accuracy: 0.3714\n",
      "Epoch 382/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3853 - val_loss: 0.4225 - val_accuracy: 0.3719\n",
      "Epoch 383/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3845 - val_loss: 0.4225 - val_accuracy: 0.3705\n",
      "Epoch 384/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.3845 - val_loss: 0.4225 - val_accuracy: 0.3729\n",
      "Epoch 385/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3862 - val_loss: 0.4238 - val_accuracy: 0.3719\n",
      "Epoch 386/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3840 - val_loss: 0.4226 - val_accuracy: 0.3690\n",
      "Epoch 387/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3860 - val_loss: 0.4235 - val_accuracy: 0.3775\n",
      "Epoch 388/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3850 - val_loss: 0.4228 - val_accuracy: 0.3705\n",
      "Epoch 389/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3858 - val_loss: 0.4218 - val_accuracy: 0.3703\n",
      "Epoch 390/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3864 - val_loss: 0.4225 - val_accuracy: 0.3784\n",
      "Epoch 391/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3937 - val_loss: 0.4232 - val_accuracy: 0.3740\n",
      "Epoch 392/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3861 - val_loss: 0.4217 - val_accuracy: 0.3673\n",
      "Epoch 393/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3842 - val_loss: 0.4221 - val_accuracy: 0.3679\n",
      "Epoch 394/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3836 - val_loss: 0.4228 - val_accuracy: 0.3690\n",
      "Epoch 395/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3844 - val_loss: 0.4243 - val_accuracy: 0.3695\n",
      "Epoch 396/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3865 - val_loss: 0.4224 - val_accuracy: 0.3716\n",
      "Epoch 397/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3847 - val_loss: 0.4231 - val_accuracy: 0.3703\n",
      "Epoch 398/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3862 - val_loss: 0.4230 - val_accuracy: 0.3720\n",
      "Epoch 399/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3853 - val_loss: 0.4243 - val_accuracy: 0.3695\n",
      "Epoch 400/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3860 - val_loss: 0.4229 - val_accuracy: 0.3682\n",
      "Epoch 401/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3850 - val_loss: 0.4224 - val_accuracy: 0.3695\n",
      "Epoch 402/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3838 - val_loss: 0.4221 - val_accuracy: 0.3695\n",
      "Epoch 403/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3853 - val_loss: 0.4231 - val_accuracy: 0.3698\n",
      "Epoch 404/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3854 - val_loss: 0.4225 - val_accuracy: 0.3693\n",
      "Epoch 405/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3853 - val_loss: 0.4235 - val_accuracy: 0.3700\n",
      "Epoch 406/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3866 - val_loss: 0.4227 - val_accuracy: 0.3718\n",
      "Epoch 407/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3863 - val_loss: 0.4224 - val_accuracy: 0.3703\n",
      "Epoch 408/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3845 - val_loss: 0.4235 - val_accuracy: 0.3677\n",
      "Epoch 409/5000\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.38 - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3838 - val_loss: 0.4234 - val_accuracy: 0.3695\n",
      "Epoch 410/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3837 - val_loss: 0.4236 - val_accuracy: 0.3677\n",
      "Epoch 411/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3839 - val_loss: 0.4239 - val_accuracy: 0.3680\n",
      "Epoch 412/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3844 - val_loss: 0.4217 - val_accuracy: 0.3695\n",
      "Epoch 413/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3849 - val_loss: 0.4233 - val_accuracy: 0.3692\n",
      "Epoch 414/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3857 - val_loss: 0.4227 - val_accuracy: 0.3715\n",
      "Epoch 415/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3863 - val_loss: 0.4228 - val_accuracy: 0.3695\n",
      "Epoch 416/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3849 - val_loss: 0.4235 - val_accuracy: 0.3694\n",
      "Epoch 417/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3838 - val_loss: 0.4237 - val_accuracy: 0.3690\n",
      "Epoch 418/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3851 - val_loss: 0.4222 - val_accuracy: 0.3696\n",
      "Epoch 419/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3853 - val_loss: 0.4223 - val_accuracy: 0.3708\n",
      "Epoch 420/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3854 - val_loss: 0.4223 - val_accuracy: 0.3692\n",
      "Epoch 421/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.3846 - val_loss: 0.4224 - val_accuracy: 0.3689\n",
      "Epoch 422/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3850 - val_loss: 0.4223 - val_accuracy: 0.3694\n",
      "Epoch 423/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3846 - val_loss: 0.4236 - val_accuracy: 0.3696\n",
      "Epoch 424/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3855 - val_loss: 0.4239 - val_accuracy: 0.3690\n",
      "Epoch 425/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3841 - val_loss: 0.4232 - val_accuracy: 0.3713\n",
      "Epoch 426/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3849 - val_loss: 0.4223 - val_accuracy: 0.3682\n",
      "Epoch 427/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3832 - val_loss: 0.4232 - val_accuracy: 0.3696\n",
      "Epoch 428/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3855 - val_loss: 0.4222 - val_accuracy: 0.3687\n",
      "Epoch 429/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3850 - val_loss: 0.4231 - val_accuracy: 0.3709\n",
      "Epoch 430/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3848 - val_loss: 0.4220 - val_accuracy: 0.3678\n",
      "Epoch 431/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3843 - val_loss: 0.4205 - val_accuracy: 0.3690\n",
      "Epoch 432/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3883 - val_loss: 0.4216 - val_accuracy: 0.3701\n",
      "Epoch 433/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3835 - val_loss: 0.4214 - val_accuracy: 0.3709\n",
      "Epoch 434/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3834 - val_loss: 0.4229 - val_accuracy: 0.3709\n",
      "Epoch 435/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3837 - val_loss: 0.4229 - val_accuracy: 0.3680\n",
      "Epoch 436/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.3823 - val_loss: 0.4213 - val_accuracy: 0.3672\n",
      "Epoch 437/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3835 - val_loss: 0.4219 - val_accuracy: 0.3672\n",
      "Epoch 438/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3847 - val_loss: 0.4226 - val_accuracy: 0.3701\n",
      "Epoch 439/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.3842 - val_loss: 0.4216 - val_accuracy: 0.3688\n",
      "Epoch 440/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3889 - val_loss: 0.4223 - val_accuracy: 0.3766\n",
      "Epoch 441/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3850 - val_loss: 0.4227 - val_accuracy: 0.3688\n",
      "Epoch 442/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3834 - val_loss: 0.4214 - val_accuracy: 0.3690\n",
      "Epoch 443/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3853 - val_loss: 0.4228 - val_accuracy: 0.3704\n",
      "Epoch 444/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3839 - val_loss: 0.4227 - val_accuracy: 0.3692\n",
      "Epoch 445/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3833 - val_loss: 0.4231 - val_accuracy: 0.3687\n",
      "Epoch 446/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3831 - val_loss: 0.4215 - val_accuracy: 0.3674\n",
      "Epoch 447/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3841 - val_loss: 0.4212 - val_accuracy: 0.3685\n",
      "Epoch 448/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3829 - val_loss: 0.4216 - val_accuracy: 0.3683\n",
      "Epoch 449/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3826 - val_loss: 0.4222 - val_accuracy: 0.3687\n",
      "Epoch 450/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3839 - val_loss: 0.4225 - val_accuracy: 0.3677\n",
      "Epoch 451/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3837 - val_loss: 0.4233 - val_accuracy: 0.3701\n",
      "Epoch 452/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3830 - val_loss: 0.4222 - val_accuracy: 0.3669\n",
      "Epoch 453/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3846 - val_loss: 0.4233 - val_accuracy: 0.3672\n",
      "Epoch 454/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3836 - val_loss: 0.4218 - val_accuracy: 0.3715\n",
      "Epoch 455/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3830 - val_loss: 0.4241 - val_accuracy: 0.3773\n",
      "Epoch 456/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.3924 - val_loss: 0.4274 - val_accuracy: 0.3720\n",
      "Epoch 457/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.3886 - val_loss: 0.4200 - val_accuracy: 0.3689\n",
      "Epoch 458/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3844 - val_loss: 0.4234 - val_accuracy: 0.3758\n",
      "Epoch 459/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3873 - val_loss: 0.4215 - val_accuracy: 0.3803\n",
      "Epoch 460/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3957 - val_loss: 0.4228 - val_accuracy: 0.3700\n",
      "Epoch 461/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3891 - val_loss: 0.4223 - val_accuracy: 0.3780\n",
      "Epoch 462/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.4016 - val_loss: 0.4238 - val_accuracy: 0.3869\n",
      "Epoch 463/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.4007 - val_loss: 0.4216 - val_accuracy: 0.3781\n",
      "Epoch 464/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3897 - val_loss: 0.4201 - val_accuracy: 0.3684\n",
      "Epoch 465/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3839 - val_loss: 0.4219 - val_accuracy: 0.3728\n",
      "Epoch 466/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3907 - val_loss: 0.4229 - val_accuracy: 0.3736\n",
      "Epoch 467/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3934 - val_loss: 0.4223 - val_accuracy: 0.3716\n",
      "Epoch 468/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3866 - val_loss: 0.4204 - val_accuracy: 0.3682\n",
      "Epoch 469/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3889 - val_loss: 0.4223 - val_accuracy: 0.3780\n",
      "Epoch 470/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3915 - val_loss: 0.4235 - val_accuracy: 0.3780\n",
      "Epoch 471/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3907 - val_loss: 0.4227 - val_accuracy: 0.3781\n",
      "Epoch 472/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.4019 - val_loss: 0.4234 - val_accuracy: 0.3810\n",
      "Epoch 473/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3930 - val_loss: 0.4221 - val_accuracy: 0.3753\n",
      "Epoch 474/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3856 - val_loss: 0.4216 - val_accuracy: 0.3668\n",
      "Epoch 475/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3842 - val_loss: 0.4211 - val_accuracy: 0.3748\n",
      "Epoch 476/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3898 - val_loss: 0.4223 - val_accuracy: 0.3670\n",
      "Epoch 477/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3868 - val_loss: 0.4225 - val_accuracy: 0.3784\n",
      "Epoch 478/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3938 - val_loss: 0.4249 - val_accuracy: 0.3784\n",
      "Epoch 479/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.3860 - val_loss: 0.4211 - val_accuracy: 0.3689\n",
      "Epoch 480/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3824 - val_loss: 0.4237 - val_accuracy: 0.3673\n",
      "Epoch 481/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3829 - val_loss: 0.4211 - val_accuracy: 0.3665\n",
      "Epoch 482/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3861 - val_loss: 0.4204 - val_accuracy: 0.3644\n",
      "Epoch 483/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3849 - val_loss: 0.4220 - val_accuracy: 0.3749\n",
      "Epoch 484/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3898 - val_loss: 0.4237 - val_accuracy: 0.3670\n",
      "Epoch 485/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3849 - val_loss: 0.4221 - val_accuracy: 0.3690\n",
      "Epoch 486/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3827 - val_loss: 0.4232 - val_accuracy: 0.3689\n",
      "Epoch 487/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3842 - val_loss: 0.4230 - val_accuracy: 0.3680\n",
      "Epoch 488/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3837 - val_loss: 0.4230 - val_accuracy: 0.3683\n",
      "Epoch 489/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3915 - val_loss: 0.4219 - val_accuracy: 0.3749\n",
      "Epoch 490/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3883 - val_loss: 0.4211 - val_accuracy: 0.3729\n",
      "Epoch 491/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3878 - val_loss: 0.4224 - val_accuracy: 0.3655\n",
      "Epoch 492/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3854 - val_loss: 0.4229 - val_accuracy: 0.3699\n",
      "Epoch 493/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3836 - val_loss: 0.4212 - val_accuracy: 0.3670\n",
      "Epoch 494/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3845 - val_loss: 0.4218 - val_accuracy: 0.3684\n",
      "Epoch 495/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3829 - val_loss: 0.4225 - val_accuracy: 0.3665\n",
      "Epoch 496/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3828 - val_loss: 0.4213 - val_accuracy: 0.3680\n",
      "Epoch 497/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3840 - val_loss: 0.4228 - val_accuracy: 0.3678\n",
      "Epoch 498/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3853 - val_loss: 0.4225 - val_accuracy: 0.3679\n",
      "Epoch 499/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3855 - val_loss: 0.4217 - val_accuracy: 0.3675\n",
      "Epoch 500/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3839 - val_loss: 0.4230 - val_accuracy: 0.3678\n",
      "Epoch 501/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3848 - val_loss: 0.4222 - val_accuracy: 0.3769\n",
      "Epoch 502/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3921 - val_loss: 0.4217 - val_accuracy: 0.3724\n",
      "Epoch 503/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3870 - val_loss: 0.4232 - val_accuracy: 0.3733\n",
      "Epoch 504/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3854 - val_loss: 0.4226 - val_accuracy: 0.3689\n",
      "Epoch 505/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3835 - val_loss: 0.4232 - val_accuracy: 0.3677\n",
      "Epoch 506/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3827 - val_loss: 0.4221 - val_accuracy: 0.3679\n",
      "Epoch 507/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3849 - val_loss: 0.4195 - val_accuracy: 0.3683\n",
      "Epoch 508/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3831 - val_loss: 0.4220 - val_accuracy: 0.3677\n",
      "Epoch 509/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.3831 - val_loss: 0.4222 - val_accuracy: 0.3685\n",
      "Epoch 510/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.3838 - val_loss: 0.4232 - val_accuracy: 0.3687\n",
      "Epoch 511/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3842 - val_loss: 0.4231 - val_accuracy: 0.3690\n",
      "Epoch 512/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.3842 - val_loss: 0.4252 - val_accuracy: 0.3708\n",
      "Epoch 513/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3840 - val_loss: 0.4234 - val_accuracy: 0.3665\n",
      "Epoch 514/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.3914 - val_loss: 0.4223 - val_accuracy: 0.3758\n",
      "Epoch 515/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3850 - val_loss: 0.4236 - val_accuracy: 0.3692\n",
      "Epoch 516/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3853 - val_loss: 0.4222 - val_accuracy: 0.3789\n",
      "Epoch 517/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3885 - val_loss: 0.4210 - val_accuracy: 0.3708\n",
      "Epoch 518/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.3845 - val_loss: 0.4220 - val_accuracy: 0.3701\n",
      "Epoch 519/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3899 - val_loss: 0.4215 - val_accuracy: 0.3705\n",
      "Epoch 520/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3857 - val_loss: 0.4205 - val_accuracy: 0.3690\n",
      "Epoch 521/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3833 - val_loss: 0.4225 - val_accuracy: 0.3690\n",
      "Epoch 522/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3838 - val_loss: 0.4217 - val_accuracy: 0.3674\n",
      "Epoch 523/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3833 - val_loss: 0.4200 - val_accuracy: 0.3695\n",
      "Epoch 524/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3847 - val_loss: 0.4229 - val_accuracy: 0.3723\n",
      "Epoch 525/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3880 - val_loss: 0.4226 - val_accuracy: 0.3701\n",
      "Epoch 526/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3844 - val_loss: 0.4220 - val_accuracy: 0.3689\n",
      "Epoch 527/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3861 - val_loss: 0.4223 - val_accuracy: 0.3694\n",
      "Epoch 528/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3837 - val_loss: 0.4217 - val_accuracy: 0.3692\n",
      "Epoch 529/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.3849 - val_loss: 0.4235 - val_accuracy: 0.3682\n",
      "Epoch 530/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3845 - val_loss: 0.4222 - val_accuracy: 0.3664\n",
      "Epoch 531/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.3839 - val_loss: 0.4232 - val_accuracy: 0.3684\n",
      "Epoch 532/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.3843 - val_loss: 0.4220 - val_accuracy: 0.3715\n",
      "Epoch 533/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3857 - val_loss: 0.4205 - val_accuracy: 0.3668\n",
      "Epoch 534/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3842 - val_loss: 0.4220 - val_accuracy: 0.3648\n",
      "Epoch 535/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.3834 - val_loss: 0.4231 - val_accuracy: 0.3692\n",
      "Epoch 536/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3856 - val_loss: 0.4238 - val_accuracy: 0.3739\n",
      "Epoch 537/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.3860 - val_loss: 0.4230 - val_accuracy: 0.3704\n",
      "Epoch 538/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.3903 - val_loss: 0.4218 - val_accuracy: 0.3705\n",
      "Epoch 539/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.3846 - val_loss: 0.4227 - val_accuracy: 0.3684\n",
      "Epoch 540/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3854 - val_loss: 0.4214 - val_accuracy: 0.3750\n",
      "Epoch 541/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3910 - val_loss: 0.4212 - val_accuracy: 0.3679\n",
      "Epoch 542/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3840 - val_loss: 0.4219 - val_accuracy: 0.3685\n",
      "Epoch 543/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3864 - val_loss: 0.4235 - val_accuracy: 0.3698\n",
      "Epoch 544/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.3847 - val_loss: 0.4219 - val_accuracy: 0.3675\n",
      "Epoch 545/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3851 - val_loss: 0.4215 - val_accuracy: 0.3675\n",
      "Epoch 546/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3897 - val_loss: 0.4226 - val_accuracy: 0.3728\n",
      "Epoch 547/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3934 - val_loss: 0.4228 - val_accuracy: 0.3785\n",
      "Epoch 548/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.3975 - val_loss: 0.4214 - val_accuracy: 0.3803\n",
      "Epoch 549/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3999 - val_loss: 0.4232 - val_accuracy: 0.3814\n",
      "Epoch 550/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.4001 - val_loss: 0.4231 - val_accuracy: 0.3813\n",
      "Epoch 551/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.4034 - val_loss: 0.4228 - val_accuracy: 0.3829\n",
      "Epoch 552/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3975 - val_loss: 0.4223 - val_accuracy: 0.3764\n",
      "Epoch 553/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3957 - val_loss: 0.4226 - val_accuracy: 0.3743\n",
      "Epoch 554/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3880 - val_loss: 0.4228 - val_accuracy: 0.3771\n",
      "Epoch 555/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3939 - val_loss: 0.4229 - val_accuracy: 0.3759\n",
      "Epoch 556/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3912 - val_loss: 0.4215 - val_accuracy: 0.3738\n",
      "Epoch 557/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3894 - val_loss: 0.4217 - val_accuracy: 0.3751\n",
      "Epoch 558/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.3937 - val_loss: 0.4236 - val_accuracy: 0.3784\n",
      "Epoch 559/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3902 - val_loss: 0.4219 - val_accuracy: 0.3738\n",
      "Epoch 560/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3872 - val_loss: 0.4229 - val_accuracy: 0.3670\n",
      "Epoch 561/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3835 - val_loss: 0.4226 - val_accuracy: 0.3657\n",
      "Epoch 562/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.3845 - val_loss: 0.4222 - val_accuracy: 0.3769\n",
      "Epoch 563/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3956 - val_loss: 0.4231 - val_accuracy: 0.3813\n",
      "Epoch 564/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.3937 - val_loss: 0.4240 - val_accuracy: 0.3763\n",
      "Epoch 565/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.4017 - val_loss: 0.4222 - val_accuracy: 0.3809\n",
      "Epoch 566/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.4101 - val_loss: 0.4227 - val_accuracy: 0.3966\n",
      "Epoch 567/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4129 - val_loss: 0.4229 - val_accuracy: 0.3930\n",
      "Epoch 568/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.4099 - val_loss: 0.4215 - val_accuracy: 0.3936\n",
      "Epoch 569/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.4316 - val_loss: 0.4219 - val_accuracy: 0.4048\n",
      "Epoch 570/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.4435 - val_loss: 0.4241 - val_accuracy: 0.4115\n",
      "Epoch 571/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.4004 - val_loss: 0.4233 - val_accuracy: 0.3836\n",
      "Epoch 572/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.4070 - val_loss: 0.4217 - val_accuracy: 0.3899\n",
      "Epoch 573/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4034 - val_loss: 0.4215 - val_accuracy: 0.3865\n",
      "Epoch 574/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4102 - val_loss: 0.4236 - val_accuracy: 0.4011\n",
      "Epoch 575/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.4226 - val_loss: 0.4224 - val_accuracy: 0.4075\n",
      "Epoch 576/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4112 - val_loss: 0.4203 - val_accuracy: 0.3770\n",
      "Epoch 577/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.3999 - val_loss: 0.4225 - val_accuracy: 0.3847\n",
      "Epoch 578/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.3998 - val_loss: 0.4224 - val_accuracy: 0.3886\n",
      "Epoch 579/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4077 - val_loss: 0.4207 - val_accuracy: 0.3925\n",
      "Epoch 580/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.4536 - val_loss: 0.4196 - val_accuracy: 0.3901\n",
      "Epoch 581/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.4059 - val_loss: 0.4221 - val_accuracy: 0.3894\n",
      "Epoch 582/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.4373 - val_loss: 0.4221 - val_accuracy: 0.3940\n",
      "Epoch 583/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.4059 - val_loss: 0.4222 - val_accuracy: 0.3902\n",
      "Epoch 584/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.4523 - val_loss: 0.4223 - val_accuracy: 0.5002\n",
      "Epoch 585/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.4951 - val_loss: 0.4215 - val_accuracy: 0.3987\n",
      "Epoch 586/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.5056 - val_loss: 0.4216 - val_accuracy: 0.3916\n",
      "Epoch 587/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.4310 - val_loss: 0.4220 - val_accuracy: 0.3942\n",
      "Epoch 588/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.4111 - val_loss: 0.4228 - val_accuracy: 0.3941\n",
      "Epoch 589/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4131 - val_loss: 0.4233 - val_accuracy: 0.4021\n",
      "Epoch 590/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.4197 - val_loss: 0.4222 - val_accuracy: 0.5319\n",
      "Epoch 591/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5399 - val_loss: 0.4220 - val_accuracy: 0.3922\n",
      "Epoch 592/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4638 - val_loss: 0.4230 - val_accuracy: 0.5496\n",
      "Epoch 593/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.4840 - val_loss: 0.4219 - val_accuracy: 0.4871\n",
      "Epoch 594/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.5407 - val_loss: 0.4215 - val_accuracy: 0.5661\n",
      "Epoch 595/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.5509 - val_loss: 0.4222 - val_accuracy: 0.3880\n",
      "Epoch 596/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.4572 - val_loss: 0.4239 - val_accuracy: 0.6006\n",
      "Epoch 597/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5570 - val_loss: 0.4218 - val_accuracy: 0.5793\n",
      "Epoch 598/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.5976 - val_loss: 0.4209 - val_accuracy: 0.5380\n",
      "Epoch 599/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5536 - val_loss: 0.4225 - val_accuracy: 0.6286\n",
      "Epoch 600/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.5496 - val_loss: 0.4212 - val_accuracy: 0.5701\n",
      "Epoch 601/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.5121 - val_loss: 0.4206 - val_accuracy: 0.5149\n",
      "Epoch 602/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6182 - val_loss: 0.4220 - val_accuracy: 0.4008\n",
      "Epoch 603/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.5769 - val_loss: 0.4197 - val_accuracy: 0.6226\n",
      "Epoch 604/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.6413 - val_loss: 0.4216 - val_accuracy: 0.6533\n",
      "Epoch 605/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6685 - val_loss: 0.4215 - val_accuracy: 0.6523\n",
      "Epoch 606/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6642 - val_loss: 0.4235 - val_accuracy: 0.7128\n",
      "Epoch 607/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6654 - val_loss: 0.4217 - val_accuracy: 0.6599\n",
      "Epoch 608/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6632 - val_loss: 0.4228 - val_accuracy: 0.6709\n",
      "Epoch 609/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6173 - val_loss: 0.4223 - val_accuracy: 0.6514\n",
      "Epoch 610/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5999 - val_loss: 0.4212 - val_accuracy: 0.4041\n",
      "Epoch 611/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.5423 - val_loss: 0.4200 - val_accuracy: 0.5407\n",
      "Epoch 612/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5706 - val_loss: 0.4218 - val_accuracy: 0.3829\n",
      "Epoch 613/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.4822 - val_loss: 0.4210 - val_accuracy: 0.5481\n",
      "Epoch 614/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5481 - val_loss: 0.4218 - val_accuracy: 0.6270\n",
      "Epoch 615/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5879 - val_loss: 0.4212 - val_accuracy: 0.4130\n",
      "Epoch 616/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.6442 - val_loss: 0.4224 - val_accuracy: 0.6680\n",
      "Epoch 617/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6148 - val_loss: 0.4217 - val_accuracy: 0.6254\n",
      "Epoch 618/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5866 - val_loss: 0.4232 - val_accuracy: 0.3946\n",
      "Epoch 619/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.5361 - val_loss: 0.4221 - val_accuracy: 0.6788\n",
      "Epoch 620/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.5689 - val_loss: 0.4230 - val_accuracy: 0.6693\n",
      "Epoch 621/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6741 - val_loss: 0.4213 - val_accuracy: 0.6441\n",
      "Epoch 622/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6594 - val_loss: 0.4214 - val_accuracy: 0.6332\n",
      "Epoch 623/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.6483 - val_loss: 0.4196 - val_accuracy: 0.6179\n",
      "Epoch 624/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.6645 - val_loss: 0.4224 - val_accuracy: 0.6863\n",
      "Epoch 625/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.6978 - val_loss: 0.4208 - val_accuracy: 0.7027\n",
      "Epoch 626/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6977 - val_loss: 0.4222 - val_accuracy: 0.6397\n",
      "Epoch 627/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6391 - val_loss: 0.4219 - val_accuracy: 0.6531\n",
      "Epoch 628/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.6395 - val_loss: 0.4212 - val_accuracy: 0.6008\n",
      "Epoch 629/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.4832 - val_loss: 0.4216 - val_accuracy: 0.3847\n",
      "Epoch 630/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5251 - val_loss: 0.4196 - val_accuracy: 0.5789\n",
      "Epoch 631/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.6437 - val_loss: 0.4241 - val_accuracy: 0.6942\n",
      "Epoch 632/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.6625 - val_loss: 0.4230 - val_accuracy: 0.7127\n",
      "Epoch 633/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.6939 - val_loss: 0.4223 - val_accuracy: 0.6813\n",
      "Epoch 634/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6522 - val_loss: 0.4203 - val_accuracy: 0.6083\n",
      "Epoch 635/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.5709 - val_loss: 0.4226 - val_accuracy: 0.5266\n",
      "Epoch 636/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6040 - val_loss: 0.4227 - val_accuracy: 0.6658\n",
      "Epoch 637/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.5198 - val_loss: 0.4215 - val_accuracy: 0.3869\n",
      "Epoch 638/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4238 - val_loss: 0.4218 - val_accuracy: 0.3866\n",
      "Epoch 639/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4109 - val_loss: 0.4214 - val_accuracy: 0.3828\n",
      "Epoch 640/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.3968 - val_loss: 0.4228 - val_accuracy: 0.3741\n",
      "Epoch 641/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.4185 - val_loss: 0.4236 - val_accuracy: 0.3838\n",
      "Epoch 642/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.3961 - val_loss: 0.4235 - val_accuracy: 0.3831\n",
      "Epoch 643/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.4008 - val_loss: 0.4207 - val_accuracy: 0.3902\n",
      "Epoch 644/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.4868 - val_loss: 0.4214 - val_accuracy: 0.3864\n",
      "Epoch 645/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.5083 - val_loss: 0.4241 - val_accuracy: 0.6915\n",
      "Epoch 646/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.5324 - val_loss: 0.4225 - val_accuracy: 0.4063\n",
      "Epoch 647/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.4085 - val_loss: 0.4231 - val_accuracy: 0.3976\n",
      "Epoch 648/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.5126 - val_loss: 0.4220 - val_accuracy: 0.4128\n",
      "Epoch 649/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.5224 - val_loss: 0.4224 - val_accuracy: 0.6254\n",
      "Epoch 650/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6273 - val_loss: 0.4209 - val_accuracy: 0.6118\n",
      "Epoch 651/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.6532 - val_loss: 0.4222 - val_accuracy: 0.6735\n",
      "Epoch 652/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.6620 - val_loss: 0.4209 - val_accuracy: 0.6078\n",
      "Epoch 653/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6530 - val_loss: 0.4217 - val_accuracy: 0.6280\n",
      "Epoch 654/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.6258 - val_loss: 0.4225 - val_accuracy: 0.6397\n",
      "Epoch 655/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6005 - val_loss: 0.4229 - val_accuracy: 0.6355\n",
      "Epoch 656/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.5642 - val_loss: 0.4220 - val_accuracy: 0.6040\n",
      "Epoch 657/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.5576 - val_loss: 0.4242 - val_accuracy: 0.5927\n",
      "Epoch 658/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.5806 - val_loss: 0.4233 - val_accuracy: 0.6035\n",
      "Epoch 659/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.5503 - val_loss: 0.4221 - val_accuracy: 0.5982\n",
      "Epoch 660/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5746 - val_loss: 0.4217 - val_accuracy: 0.5779\n",
      "Epoch 661/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.6610 - val_loss: 0.4226 - val_accuracy: 0.7081\n",
      "Epoch 662/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.6828 - val_loss: 0.4212 - val_accuracy: 0.5978\n",
      "Epoch 663/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6066 - val_loss: 0.4227 - val_accuracy: 0.6323\n",
      "Epoch 664/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.6529 - val_loss: 0.4213 - val_accuracy: 0.6274\n",
      "Epoch 665/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.6287 - val_loss: 0.4230 - val_accuracy: 0.6461\n",
      "Epoch 666/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.6359 - val_loss: 0.4230 - val_accuracy: 0.6136\n",
      "Epoch 667/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.6129 - val_loss: 0.4230 - val_accuracy: 0.6358\n",
      "Epoch 668/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.6323 - val_loss: 0.4228 - val_accuracy: 0.5880\n",
      "Epoch 669/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.6337 - val_loss: 0.4204 - val_accuracy: 0.5698\n",
      "Epoch 670/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5931 - val_loss: 0.4232 - val_accuracy: 0.6120\n",
      "Epoch 671/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.5901 - val_loss: 0.4189 - val_accuracy: 0.5134\n",
      "Epoch 672/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.6085 - val_loss: 0.4215 - val_accuracy: 0.5894\n",
      "Epoch 673/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6147 - val_loss: 0.4228 - val_accuracy: 0.6373\n",
      "Epoch 674/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.6339 - val_loss: 0.4225 - val_accuracy: 0.6177\n",
      "Epoch 675/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6162 - val_loss: 0.4222 - val_accuracy: 0.5834\n",
      "Epoch 676/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.5992 - val_loss: 0.4231 - val_accuracy: 0.6084\n",
      "Epoch 677/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.6054 - val_loss: 0.4224 - val_accuracy: 0.6177\n",
      "Epoch 678/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.6074 - val_loss: 0.4227 - val_accuracy: 0.5850\n",
      "Epoch 679/5000\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.5899 - val_loss: 0.4225 - val_accuracy: 0.6171\n",
      "Epoch 680/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.5963 - val_loss: 0.4241 - val_accuracy: 0.6090\n",
      "Epoch 681/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5347 - val_loss: 0.4219 - val_accuracy: 0.4855\n",
      "Epoch 682/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.5664 - val_loss: 0.4237 - val_accuracy: 0.6162\n",
      "Epoch 683/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.5880 - val_loss: 0.4229 - val_accuracy: 0.5834\n",
      "Epoch 684/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.5218 - val_loss: 0.4226 - val_accuracy: 0.5117\n",
      "Epoch 685/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.5704 - val_loss: 0.4223 - val_accuracy: 0.5732\n",
      "Epoch 686/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.5653 - val_loss: 0.4229 - val_accuracy: 0.6538\n",
      "Epoch 687/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.6330 - val_loss: 0.4220 - val_accuracy: 0.6291\n",
      "Epoch 688/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.6079 - val_loss: 0.4225 - val_accuracy: 0.6124\n",
      "Epoch 689/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6241 - val_loss: 0.4210 - val_accuracy: 0.5990\n",
      "Epoch 690/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.6544 - val_loss: 0.4214 - val_accuracy: 0.6004\n",
      "Epoch 691/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.6663 - val_loss: 0.4224 - val_accuracy: 0.6574\n",
      "Epoch 692/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6497 - val_loss: 0.4235 - val_accuracy: 0.6939\n",
      "Epoch 693/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6839 - val_loss: 0.4225 - val_accuracy: 0.6650\n",
      "Epoch 694/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6711 - val_loss: 0.4227 - val_accuracy: 0.6754\n",
      "Epoch 695/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.6849 - val_loss: 0.4221 - val_accuracy: 0.6548\n",
      "Epoch 696/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.6629 - val_loss: 0.4223 - val_accuracy: 0.6266\n",
      "Epoch 697/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6659 - val_loss: 0.4235 - val_accuracy: 0.6884\n",
      "Epoch 698/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.6660 - val_loss: 0.4221 - val_accuracy: 0.6971\n",
      "Epoch 699/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.6878 - val_loss: 0.4233 - val_accuracy: 0.6839\n",
      "Epoch 700/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.6686 - val_loss: 0.4214 - val_accuracy: 0.6418\n",
      "Epoch 701/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.6504 - val_loss: 0.4231 - val_accuracy: 0.6299\n",
      "Epoch 702/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.6277 - val_loss: 0.4219 - val_accuracy: 0.5756\n",
      "Epoch 703/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.6527 - val_loss: 0.4218 - val_accuracy: 0.6006\n",
      "Epoch 704/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.6121 - val_loss: 0.4233 - val_accuracy: 0.5335\n",
      "Epoch 705/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.4019 - val_loss: 0.4213 - val_accuracy: 0.3720\n",
      "Epoch 706/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.3970 - val_loss: 0.4221 - val_accuracy: 0.3843\n",
      "Epoch 707/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.6093 - val_loss: 0.4221 - val_accuracy: 0.5648\n",
      "Epoch 708/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.5473 - val_loss: 0.4237 - val_accuracy: 0.6154\n",
      "Epoch 709/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.5714 - val_loss: 0.4231 - val_accuracy: 0.6054\n",
      "Epoch 710/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5425 - val_loss: 0.4209 - val_accuracy: 0.5698\n",
      "Epoch 711/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.6077 - val_loss: 0.4240 - val_accuracy: 0.6489\n",
      "Epoch 712/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.6468 - val_loss: 0.4238 - val_accuracy: 0.6479\n",
      "Epoch 713/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5621 - val_loss: 0.4229 - val_accuracy: 0.5172\n",
      "Epoch 714/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.5759 - val_loss: 0.4232 - val_accuracy: 0.6125\n",
      "Epoch 715/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.5719 - val_loss: 0.4233 - val_accuracy: 0.5475\n",
      "Epoch 716/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.5755 - val_loss: 0.4230 - val_accuracy: 0.6231\n",
      "Epoch 717/5000\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.5981 - val_loss: 0.4234 - val_accuracy: 0.6528\n",
      "Epoch 718/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.6255 - val_loss: 0.4226 - val_accuracy: 0.6014\n",
      "Epoch 719/5000\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.6187 - val_loss: 0.4222 - val_accuracy: 0.5550\n",
      "Epoch 720/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.5341 - val_loss: 0.4233 - val_accuracy: 0.4868\n",
      "Epoch 721/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.4515 - val_loss: 0.4226 - val_accuracy: 0.4309\n",
      "Epoch 722/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.5265 - val_loss: 0.4213 - val_accuracy: 0.4957\n",
      "Epoch 723/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.5194 - val_loss: 0.4221 - val_accuracy: 0.4953\n",
      "Epoch 724/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.5249 - val_loss: 0.4226 - val_accuracy: 0.5791\n",
      "Epoch 725/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.5850 - val_loss: 0.4210 - val_accuracy: 0.5763\n",
      "Epoch 726/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6091 - val_loss: 0.4221 - val_accuracy: 0.5836\n",
      "Epoch 727/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.5680 - val_loss: 0.4238 - val_accuracy: 0.4644\n",
      "Epoch 728/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.5142 - val_loss: 0.4218 - val_accuracy: 0.5447\n",
      "Epoch 729/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.6534 - val_loss: 0.4221 - val_accuracy: 0.6096\n",
      "Epoch 730/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.6831 - val_loss: 0.4220 - val_accuracy: 0.7128\n",
      "Epoch 731/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7225 - val_loss: 0.4228 - val_accuracy: 0.6964\n",
      "Epoch 732/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7061 - val_loss: 0.4219 - val_accuracy: 0.6982\n",
      "Epoch 733/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.6463 - val_loss: 0.4215 - val_accuracy: 0.5960\n",
      "Epoch 734/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.6526 - val_loss: 0.4231 - val_accuracy: 0.6729\n",
      "Epoch 735/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.6751 - val_loss: 0.4226 - val_accuracy: 0.5892\n",
      "Epoch 736/5000\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.5701 - val_loss: 0.4217 - val_accuracy: 0.6066\n",
      "Epoch 737/5000\n",
      "59/94 [=================>............] - ETA: 0s - loss: 0.4270 - accuracy: 0.7075"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-baeef1173450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1123\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=200,\n",
    "    epochs=5000,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y\n",
    "y_predicted = model.predict(X)\n",
    "y_predicted_binary = np.where(y_predicted > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980663899960696"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_true, y_predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../Data/test_set_features.csv')\n",
    "df_full = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full.drop(columns=['employment_occupation', 'employment_industry', 'health_insurance', 'respondent_id'])\n",
    "\n",
    "categorical_columns = [\n",
    "    'sex',\n",
    "    'hhs_geo_region',\n",
    "    'census_msa',\n",
    "    'race',\n",
    "    'age_group',\n",
    "    'behavioral_face_mask',\n",
    "    'behavioral_wash_hands',\n",
    "    'behavioral_antiviral_meds',\n",
    "    'behavioral_outside_home',\n",
    "    'behavioral_large_gatherings',\n",
    "    'behavioral_touch_face',\n",
    "    'behavioral_avoidance',\n",
    "    'health_worker',\n",
    "    'child_under_6_months',\n",
    "    'chronic_med_condition',\n",
    "    'education',\n",
    "    'marital_status',\n",
    "    'employment_status',\n",
    "    'rent_or_own',\n",
    "    'doctor_recc_h1n1',\n",
    "    'doctor_recc_seasonal',\n",
    "    'income_poverty'\n",
    "]\n",
    "\n",
    "numerical_columns = [\n",
    "    'household_children',\n",
    "    'household_adults',\n",
    "    'h1n1_concern',\n",
    "    'h1n1_knowledge',\n",
    "    'opinion_h1n1_risk',\n",
    "    'opinion_h1n1_vacc_effective',\n",
    "    'opinion_h1n1_sick_from_vacc',\n",
    "    'opinion_seas_vacc_effective',\n",
    "    'opinion_seas_risk',\n",
    "    'opinion_seas_sick_from_vacc',\n",
    "    \n",
    "]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    curr_col = df[column]\n",
    "    df.loc[df[column] == 1, column] = 'Yes'\n",
    "    df.loc[df[column] == 0, column] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_columns:\n",
    "    df[column] = df[column].fillna(df[column].mean())\n",
    "\n",
    "df['health_worker'] = df['health_worker'].fillna(0)\n",
    "df['behavioral_face_mask'] = df['behavioral_face_mask'].fillna(0)\n",
    "df['behavioral_wash_hands'] = df['behavioral_wash_hands'].fillna(0)\n",
    "df['behavioral_antiviral_meds'] = df['behavioral_antiviral_meds'].fillna(0)\n",
    "df['behavioral_outside_home'] = df['behavioral_outside_home'].fillna(0)\n",
    "df['behavioral_large_gatherings'] = df['behavioral_large_gatherings'].fillna(0)\n",
    "df['behavioral_touch_face'] = df['behavioral_touch_face'].fillna(0)\n",
    "df['behavioral_avoidance'] = df['behavioral_avoidance'].fillna(0)\n",
    "df['child_under_6_months'] = df['child_under_6_months'].fillna(0)\n",
    "df['chronic_med_condition'] = df['chronic_med_condition'].fillna(0)\n",
    "df['marital_status'] = df['marital_status'].fillna('Not Married')\n",
    "df['rent_or_own'] = df['rent_or_own'].fillna('Rent')\n",
    "df['education'] = df['education'].fillna('Some College')\n",
    "df['employment_status'] = df['employment_status'].fillna('Employed')\n",
    "df['doctor_recc_h1n1'] = df['doctor_recc_h1n1'].fillna(1)\n",
    "df['doctor_recc_seasonal'] = df['doctor_recc_seasonal'].fillna(1)\n",
    "df['income_poverty'] = df['income_poverty'].fillna('<= $75,000, Above Poverty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "\n",
    "drop_these = [\n",
    "    'rent_or_own',\n",
    "    'income_poverty',\n",
    "    'employment_status',\n",
    "    'education'\n",
    "]\n",
    "\n",
    "categorical_columns = [x for x in categorical_columns if x not in drop_these]\n",
    "\n",
    "df = df.drop(columns=drop_these)\n",
    "\n",
    "\n",
    "#Get Binary Data for Categorical Variables\n",
    "cat_df = X[categorical_columns]\n",
    "recat_df = pd.get_dummies(data=cat_df)\n",
    "\n",
    "num_df = X[numerical_columns]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale Numerical Data\n",
    "scaler = StandardScaler()\n",
    "scaled_num = scaler.fit_transform(num_df)\n",
    "scaled_num_df = pd.DataFrame(scaled_num, index=num_df.index, columns=num_df.columns)\n",
    "\n",
    "encoded_df = pd.concat([recat_df, scaled_num_df], axis=1)\n",
    "\n",
    "X = np.asarray(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(X)\n",
    "y_df = pd.DataFrame(y, columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([df_full, y_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[['respondent_id', 'h1n1_vaccine', 'seasonal_vaccine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../Submissions/Submission 6.6.21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
